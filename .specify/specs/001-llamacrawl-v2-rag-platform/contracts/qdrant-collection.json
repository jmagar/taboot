{
  "_comment": "Qdrant Collection Configuration for LlamaCrawl v2",
  "_feature": "001-llamacrawl-v2-rag-platform",
  "_date": "2025-10-20",
  "_qdrant_version": "1.15.1+",
  "_gpu_required": true,

  "collection_name": "taboot.documents",

  "vectors": {
    "size": 1024,
    "distance": "Cosine",
    "on_disk": false
  },

  "hnsw_config": {
    "_comment": "HNSW (Hierarchical Navigable Small World) configuration for GPU-accelerated indexing",
    "m": 32,
    "ef_construct": 128,
    "full_scan_threshold": 10000,
    "max_indexing_threads": 0,
    "on_disk": false
  },

  "wal_config": {
    "wal_capacity_mb": 32,
    "wal_segments_ahead": 0
  },

  "optimizers_config": {
    "deleted_threshold": 0.2,
    "vacuum_min_vector_number": 1000,
    "default_segment_number": 0,
    "max_segment_size": null,
    "memmap_threshold": null,
    "indexing_threshold": 20000,
    "flush_interval_sec": 5,
    "max_optimization_threads": 1
  },

  "shard_number": 4,
  "sharding_method": "auto",
  "replication_factor": 1,
  "write_consistency_factor": 1,

  "quantization_config": null,

  "payload_schema": {
    "_comment": "Payload schema defines all metadata fields stored with each vector",
    "_field_count": 15,
    "_deduplication_key": ["sha256", "namespace"],

    "doc_id": {
      "type": "keyword",
      "indexed": true,
      "description": "UUID v4 of source document (maps to Neo4j Document.docId)",
      "validation": {
        "pattern": "^[0-9a-f]{8}-[0-9a-f]{4}-4[0-9a-f]{3}-[89ab][0-9a-f]{3}-[0-9a-f]{12}$",
        "required": true
      },
      "example": "550e8400-e29b-41d4-a716-446655440000"
    },

    "chunk_id": {
      "type": "keyword",
      "indexed": true,
      "description": "Unique chunk identifier, format: ${doc_id}:${chunk_index}. Used as Qdrant point ID.",
      "validation": {
        "pattern": "^[0-9a-f]{8}-[0-9a-f]{4}-4[0-9a-f]{3}-[89ab][0-9a-f]{3}-[0-9a-f]{12}:\\d+$",
        "required": true
      },
      "example": "550e8400-e29b-41d4-a716-446655440000:0"
    },

    "namespace": {
      "type": "keyword",
      "indexed": true,
      "description": "Logical grouping for multi-tenant filtering (e.g., 'prod-configs', 'staging-docs')",
      "validation": {
        "pattern": "^[a-z0-9][a-z0-9_-]{0,63}$",
        "required": true
      },
      "example": "prod-configs"
    },

    "url": {
      "type": "keyword",
      "indexed": true,
      "description": "Source URL or file path",
      "validation": {
        "required": true
      },
      "example": "https://example.com/docs/api.md"
    },

    "title": {
      "type": "keyword",
      "indexed": true,
      "description": "Document title or filename",
      "validation": {
        "required": true
      },
      "example": "API Documentation"
    },

    "source": {
      "type": "keyword",
      "indexed": true,
      "description": "Source type (ingestion adapter)",
      "validation": {
        "enum": [
          "web",
          "github",
          "reddit",
          "youtube",
          "gmail",
          "elasticsearch",
          "compose",
          "swag",
          "tailscale",
          "unifi",
          "ai_session"
        ],
        "required": true
      },
      "example": "web"
    },

    "job_id": {
      "type": "keyword",
      "indexed": true,
      "description": "Firecrawl job ID or ingestion batch ID",
      "validation": {
        "required": true
      },
      "example": "fwl_xyz123abc456"
    },

    "sha256": {
      "type": "keyword",
      "indexed": true,
      "description": "SHA-256 hash of chunk text (enables deduplication by content)",
      "validation": {
        "pattern": "^[a-f0-9]{64}$",
        "required": true
      },
      "example": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855"
    },

    "mime": {
      "type": "keyword",
      "indexed": true,
      "description": "MIME type of source content",
      "validation": {
        "pattern": "^[a-z]+/[a-z0-9.+-]+$",
        "required": true
      },
      "example": "text/markdown"
    },

    "lang": {
      "type": "keyword",
      "indexed": true,
      "description": "Language code (ISO 639-1)",
      "validation": {
        "pattern": "^[a-z]{2}$",
        "required": true
      },
      "example": "en"
    },

    "chunk_index": {
      "type": "integer",
      "indexed": true,
      "description": "Sequential chunk number within document (0-based)",
      "validation": {
        "min": 0,
        "required": true
      },
      "example": 0
    },

    "text_len": {
      "type": "integer",
      "indexed": false,
      "description": "Character count of chunk text",
      "validation": {
        "min": 1,
        "required": true
      },
      "example": 512
    },

    "created_at": {
      "type": "integer",
      "indexed": true,
      "description": "Unix timestamp (seconds since epoch) of chunk creation",
      "validation": {
        "min": 0,
        "required": true
      },
      "example": 1729428000
    },

    "updated_at": {
      "type": "integer",
      "indexed": true,
      "description": "Unix timestamp of last update",
      "validation": {
        "min": 0,
        "required": true
      },
      "example": 1729428000
    },

    "tags": {
      "type": "keyword[]",
      "indexed": true,
      "description": "Free-form tags for filtering (e.g., ['production', 'database'])",
      "validation": {
        "required": false
      },
      "example": ["production", "nginx", "web-server"]
    }
  },

  "initialization_script": {
    "_comment": "Python script to create collection with this configuration",
    "_language": "python",
    "_code": [
      "from qdrant_client import QdrantClient",
      "from qdrant_client.models import VectorParams, Distance, HnswConfigDiff, OptimizersConfigDiff",
      "",
      "client = QdrantClient(url='http://taboot-vectors:6333')",
      "",
      "# Create collection with GPU-optimized HNSW config",
      "client.create_collection(",
      "    collection_name='taboot.documents',",
      "    vectors_config=VectorParams(",
      "        size=1024,",
      "        distance=Distance.COSINE,",
      "        on_disk=False  # Keep in GPU memory for fast search",
      "    ),",
      "    hnsw_config=HnswConfigDiff(",
      "        m=32,  # Number of bi-directional links per element",
      "        ef_construct=128,  # Construction time trade-off parameter",
      "        full_scan_threshold=10000,  # Use brute-force below this count",
      "        max_indexing_threads=0,  # Auto-detect optimal thread count",
      "        on_disk=False  # GPU-accelerated indexing",
      "    ),",
      "    optimizers_config=OptimizersConfigDiff(",
      "        deleted_threshold=0.2,  # Rebuild segment if 20% deleted",
      "        vacuum_min_vector_number=1000,  # Minimum vectors for vacuum",
      "        indexing_threshold=20000,  # Start indexing after 20k vectors",
      "        flush_interval_sec=5,  # Flush WAL every 5 seconds",
      "        max_optimization_threads=1  # Single-threaded optimization",
      "    ),",
      "    shard_number=4,  # 4 shards for parallel processing",
      "    replication_factor=1,  # Single-node deployment (increase for HA)",
      "    write_consistency_factor=1",
      ")",
      "",
      "# Create payload indexes for all keyword fields",
      "client.create_payload_index(",
      "    collection_name='taboot.documents',",
      "    field_name='doc_id',",
      "    field_schema='keyword'",
      ")",
      "",
      "client.create_payload_index(",
      "    collection_name='taboot.documents',",
      "    field_name='chunk_id',",
      "    field_schema='keyword'",
      ")",
      "",
      "client.create_payload_index(",
      "    collection_name='taboot.documents',",
      "    field_name='namespace',",
      "    field_schema='keyword'",
      ")",
      "",
      "client.create_payload_index(",
      "    collection_name='taboot.documents',",
      "    field_name='source',",
      "    field_schema='keyword'",
      ")",
      "",
      "client.create_payload_index(",
      "    collection_name='taboot.documents',",
      "    field_name='sha256',",
      "    field_schema='keyword'",
      ")",
      "",
      "client.create_payload_index(",
      "    collection_name='taboot.documents',",
      "    field_name='chunk_index',",
      "    field_schema='integer'",
      ")",
      "",
      "client.create_payload_index(",
      "    collection_name='taboot.documents',",
      "    field_name='created_at',",
      "    field_schema='integer'",
      ")",
      "",
      "client.create_payload_index(",
      "    collection_name='taboot.documents',",
      "    field_name='tags',",
      "    field_schema='keyword'",
      ")",
      "",
      "print('Collection taboot.documents created successfully')"
    ]
  },

  "deduplication_example": {
    "_comment": "Example logic for deduplicating chunks by (sha256, namespace) tuple",
    "_language": "python",
    "_code": [
      "from qdrant_client import QdrantClient, models",
      "from hashlib import sha256",
      "from datetime import datetime",
      "",
      "def upsert_chunk_idempotent(",
      "    client: QdrantClient,",
      "    chunk_id: str,",
      "    embedding: list[float],",
      "    payload: dict",
      ") -> None:",
      "    '''Idempotent upsert with deduplication by (sha256, namespace).'''",
      "    ",
      "    # Check for existing chunk with same content hash and namespace",
      "    existing = client.scroll(",
      "        collection_name='taboot.documents',",
      "        scroll_filter=models.Filter(",
      "            must=[",
      "                models.FieldCondition(",
      "                    key='sha256',",
      "                    match=models.MatchValue(value=payload['sha256'])",
      "                ),",
      "                models.FieldCondition(",
      "                    key='namespace',",
      "                    match=models.MatchValue(value=payload['namespace'])",
      "                )",
      "            ]",
      "        ),",
      "        limit=1",
      "    )",
      "    ",
      "    if existing[0]:  # Duplicate found",
      "        # Update metadata only, preserve existing embedding",
      "        client.set_payload(",
      "            collection_name='taboot.documents',",
      "            payload={'updated_at': int(datetime.now().timestamp())},",
      "            points=[existing[0][0].id]",
      "        )",
      "        print(f'Chunk {chunk_id} already exists, updated timestamp')",
      "    else:  # New chunk",
      "        # Insert new point",
      "        client.upsert(",
      "            collection_name='taboot.documents',",
      "            points=[models.PointStruct(",
      "                id=chunk_id,",
      "                vector=embedding,",
      "                payload=payload",
      "            )]",
      "        )",
      "        print(f'Chunk {chunk_id} inserted successfully')"
    ]
  },

  "query_examples": {
    "_comment": "Example queries using Qdrant filters",

    "search_by_namespace": {
      "description": "Vector search filtered by namespace",
      "code": [
        "from qdrant_client import models",
        "",
        "results = client.search(",
        "    collection_name='taboot.documents',",
        "    query_vector=query_embedding,  # 1024-dim vector from TEI",
        "    query_filter=models.Filter(",
        "        must=[",
        "            models.FieldCondition(",
        "                key='namespace',",
        "                match=models.MatchValue(value='prod-configs')",
        "            )",
        "        ]",
        "    ),",
        "    limit=100",
        ")"
      ]
    },

    "search_by_source_and_tags": {
      "description": "Filter by source type and tags",
      "code": [
        "results = client.search(",
        "    collection_name='taboot.documents',",
        "    query_vector=query_embedding,",
        "    query_filter=models.Filter(",
        "        must=[",
        "            models.FieldCondition(",
        "                key='source',",
        "                match=models.MatchValue(value='compose')",
        "            ),",
        "            models.FieldCondition(",
        "                key='tags',",
        "                match=models.MatchAny(any=['production', 'database'])",
        "            )",
        "        ]",
        "    ),",
        "    limit=100",
        ")"
      ]
    },

    "search_by_date_range": {
      "description": "Filter by ingestion date range",
      "code": [
        "from datetime import datetime, timedelta",
        "",
        "seven_days_ago = int((datetime.now() - timedelta(days=7)).timestamp())",
        "",
        "results = client.search(",
        "    collection_name='taboot.documents',",
        "    query_vector=query_embedding,",
        "    query_filter=models.Filter(",
        "        must=[",
        "            models.FieldCondition(",
        "                key='created_at',",
        "                range=models.Range(gte=seven_days_ago)",
        "            )",
        "        ]",
        "    ),",
        "    limit=100",
        ")"
      ]
    },

    "delete_by_doc_id": {
      "description": "Delete all chunks for a document (data governance)",
      "code": [
        "client.delete(",
        "    collection_name='taboot.documents',",
        "    points_selector=models.FilterSelector(",
        "        filter=models.Filter(",
        "            must=[",
        "                models.FieldCondition(",
        "                    key='doc_id',",
        "                    match=models.MatchValue(value='550e8400-e29b-41d4-a716-446655440000')",
        "                )",
        "            ]",
        "        )",
        "    )",
        ")"
      ]
    }
  },

  "performance_tuning": {
    "_comment": "GPU-specific tuning recommendations",

    "gpu_acceleration": {
      "enabled": true,
      "device": "cuda:0",
      "memory_mb": 6144,
      "description": "RTX 4070 GPU with 12GB VRAM. Allocate ~6GB for Qdrant indexing, leaving room for TEI and Ollama."
    },

    "batch_sizes": {
      "upsert": 1000,
      "search": 100,
      "description": "Optimal batch sizes for GPU throughput. Upserts: 1000 vectors/batch. Search: 100 results before reranking."
    },

    "memory_estimates": {
      "1M_vectors_1024dim": "~4GB RAM + ~2GB GPU VRAM",
      "10M_vectors_1024dim": "~40GB RAM + ~20GB GPU VRAM (requires scaling)",
      "description": "Memory estimates for different corpus sizes. Use sharding and replication for >10M vectors."
    },

    "throughput_targets": {
      "upsert": "â‰¥5000 vectors/sec (1024-dim, batched)",
      "search": "<100ms p95 (top-k=100)",
      "description": "Expected performance on RTX 4070 with GPU-accelerated HNSW."
    }
  },

  "health_check": {
    "_comment": "Endpoints for monitoring collection health",

    "collection_info": "GET http://taboot-vectors:6333/collections/taboot.documents",
    "cluster_status": "GET http://taboot-vectors:6333/cluster",
    "collection_aliases": "GET http://taboot-vectors:6333/collections/taboot.documents/aliases"
  },

  "schema_version": "2.0.0",
  "last_updated": "2025-10-20"
}
